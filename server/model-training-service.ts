import FormData from 'form-data';
import archiver from 'archiver';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { storage } from './storage';
import { PersonalityManager } from './agents/personalities/personality-config';
import { ArchitectureValidator } from './architecture-validator';
import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';


// Image categories and prompt templates
export const IMAGE_CATEGORIES = {
  editorial: ['portrait', 'lifestyle', 'artistic'],
  professional: ['headshot', 'business', 'corporate'],
  creative: ['artistic', 'concept', 'avant-garde']
} as const;

// ‚úÖ MAYA AI INTELLIGENCE: All generation parameters controlled by Maya's personality system
// No hardcoded templates, settings, or parameters - Maya's AI makes all decisions

// üîí IMMUTABLE CORE ARCHITECTURE - TRAINING SERVICE
// Creates individual LoRA models for each user using ostris/flux-dev-lora-trainer
// Each user gets ONLY their own trained LoRA weights - NO EXCEPTIONS
export class ModelTrainingService {
  // Configure AWS S3 (use environment region for consistency)
  private static s3 = new S3Client({
    credentials: {
      accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
      secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,
    },
    region: process.env.AWS_REGION || 'us-east-1'
  });

  // Generate unique trigger word for user
  static generateTriggerWord(userId: string): string {
    // Generate consistent trigger word using clean user ID format
    // Remove special characters and ensure numeric ID for proper training
    const cleanUserId = userId.replace(/[^a-zA-Z0-9]/g, '');
    return `user${cleanUserId}`;
  }

  // Create ZIP file with user's selfie images for training
  static async createImageZip(selfieImages: string[], userId: string): Promise<string> {

    
    // Create temporary directory for ZIP creation
    const tempDir = path.join(process.cwd(), 'temp_training');
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }
    
    const zipPath = path.join(tempDir, `training_${userId}_${Date.now()}.zip`);
    
    try {
      // Create ZIP file
      const output = fs.createWriteStream(zipPath);
      const archive = archiver('zip', { zlib: { level: 9 } });
      
      archive.pipe(output);
      
      // Add each image to ZIP with proper validation and padding
      for (let i = 0; i < selfieImages.length; i++) {
        const imageData = selfieImages[i];
        
        // More flexible image validation to accept different formats
        if (!imageData.includes('data:image/') && imageData.length < 100) {
          continue;
        }
        
        // Extract base64 data and ensure proper padding (handle different formats)
        let base64Data = imageData;
        if (imageData.includes('data:image/')) {
          base64Data = imageData.replace(/^data:image\/[a-z]+;base64,/, '');
        }
        const paddedBase64 = base64Data + '='.repeat((4 - base64Data.length % 4) % 4);
        
        try {
          const imageBuffer = Buffer.from(paddedBase64, 'base64');
          
          // Validate buffer has reasonable size (at least 500 bytes for valid image - reduced for testing)
          if (imageBuffer.length < 500) {
            continue;
          }
          

          archive.append(imageBuffer, { name: `image_${i + 1}.jpg` });
        } catch (error) {
          continue;
        }
      }
      
      await archive.finalize();
      
      // Wait for the zip to be written
      await new Promise((resolve, reject) => {
        output.on('close', () => resolve(undefined));
        output.on('error', reject);
      });
      
      // FIXED: Upload ZIP to S3 so Replicate can access it (local URLs don't work)
      // This function should now use BulletproofUploadService instead
      throw new Error('Legacy training service - use BulletproofUploadService.createTrainingZip() instead');
      
    } catch (error) {
      throw error;
    }
  }

  // Start training a new model for user
  static async startModelTraining(userId: string, selfieImages: string[]): Promise<{ trainingId: string; status: string }> {

    
    try {
      // Check if user already has a model
      const existingModel = await storage.getUserModelByUserId(userId);
      if (existingModel) {
        // For retraining, we'll update the existing model
      }
      
      // Generate unique trigger word for this user
      const triggerWord = this.generateTriggerWord(userId);
      
      // For immediate testing, create a temporary training record and upload files
      // Once we resolve the API destination issue, this will be replaced with real training
      
      // Create the actual ZIP file for training
      const zipUrl = await this.createImageZip(selfieImages, userId);
      
      // NO MODEL CREATION NEEDED: LoRA weights approach outputs .safetensors file directly

      // Start FLUX LoRA training with BASE MODEL + WEIGHTS approach (OPTION A)
      const trainingResponse = await fetch('https://api.replicate.com/v1/models/ostris/flux-dev-lora-trainer/versions/26dce37af90b9d997eeb970d92e47de3064d46c300504ae376c75bef6a9022d2/trainings', {
        method: 'POST',
        headers: {
          'Authorization': `Token ${process.env.REPLICATE_API_TOKEN}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          input: {
            input_images: zipUrl,
            trigger_word: triggerWord,
            steps: 1200, // RESEARCH OPTIMAL: 1200 steps for identity vs styling balance
            learning_rate: 0.0002, // OPTIMIZED: 0.0002 = balanced training speed vs stability
            batch_size: 1, // OPTIMIZED: Single batch for precise training
            lora_rank: 32, // OPTIMIZED: 32 for complex facial features
            resolution: "1024", // OPTIMIZED: 1024x1024 ideal resolution
            optimizer: "adamw8bit", // OPTIMIZED: Memory efficient optimizer
            autocaption: true, // OPTIMIZED: FLUX works better with contextual captions
            cache_latents_to_disk: false, // OPTIMIZED: Memory optimization
            caption_dropout_rate: 0.1 // OPTIMIZED: 0.1 = better generalization
          }
          // REMOVED: destination parameter - this outputs LoRA weights instead of destination model
        })
      });

      const trainingData = await trainingResponse.json();
      
      if (!trainingResponse.ok) {
        throw new Error(`Replicate training failed: ${JSON.stringify(trainingData)}`);
      }

      
      // üîí PHASE 1 FIX: PRESERVE WORKING MODEL DATA - Critical Database Safety
      // Don't clear existing model data until replacement is confirmed working
      console.log(`üîç Storing training ID: ${trainingData.id} for user ${userId}`);
      
      // Get existing model data to preserve working functionality
      const currentModel = await storage.getUserModelByUserId(userId);
      console.log(`üîí PHASE 1: Preserving existing model data for user ${userId}`);
      console.log(`üîí PHASE 1: Existing model - ID: ${currentModel?.replicateModelId}, Version: ${currentModel?.replicateVersionId}`);
      
      await storage.updateUserModel(userId, {
        trainingId: trainingData.id, // Store training ID in dedicated field
        triggerWord: triggerWord,
        trainingStatus: 'training',
        trainingProgress: 0,
        startedAt: new Date(),
        // üîí PHASE 1 CRITICAL FIX: PRESERVE existing working model data
        // User can continue generating images while new training is in progress
        // replicateModelId: PRESERVED - don't clear until replacement is ready
        // replicateVersionId: PRESERVED - don't clear until replacement is ready
        // Only clear if no existing model data exists
        ...(currentModel?.replicateModelId ? {} : { replicateModelId: null }),
        ...(currentModel?.replicateVersionId ? {} : { replicateVersionId: null })
      });
      console.log(`‚úÖ PHASE 1: Training started while preserving working model for user ${userId}`);
      
      
      return {
        trainingId: trainingData.id,
        status: 'training'
      };
      
    } catch (error) {
      throw error;
    }
  }

  // Check training status
  static async checkTrainingStatus(userId: string): Promise<{ status: string; progress: number }> {
    try {
      const userModel = await storage.getUserModelByUserId(userId);
      if (!userModel || (!userModel.trainingId && !userModel.replicateModelId)) {
        throw new Error('No training found for user');
      }
      
      // Use trainingId if available (new architecture), otherwise fallback to replicateModelId (legacy)
      const trainingId = userModel.trainingId || userModel.replicateModelId;
      console.log(`üîç Checking training status for user ${userId}, trainingId: ${trainingId}`);
      
      // Check REAL Replicate API training status
      const trainingStatusResponse = await fetch(`https://api.replicate.com/v1/trainings/${trainingId}`, {
        headers: {
          'Authorization': `Token ${process.env.REPLICATE_API_TOKEN}`,
          'Content-Type': 'application/json'
        }
      });
      
      if (!trainingStatusResponse.ok) {
        throw new Error(`Failed to check training status: ${trainingStatusResponse.status}`);
      }
      
      const trainingData = await trainingStatusResponse.json();
      
      let progress = 0;
      let status = 'training';
      
      if (trainingData.status === 'succeeded') {
        progress = 100;
        status = 'completed';
      } else if (trainingData.status === 'failed') {
        status = 'failed';
        progress = 0;
      } else if (trainingData.status === 'canceled') {
        status = 'cancelled';
        progress = 0;
      } else {
        // üìä PHASE 4: Enhanced progress tracking with real Replicate logs
        progress = await this.calculateRealTrainingProgress(trainingData, userModel);
        console.log(`üìä PHASE 4: Real progress calculated: ${progress}% for user ${userId}`);
      }
      
      // Update model with real status and version ID when training completes
      const updateData: any = {
        trainingStatus: status,
        trainingProgress: progress
      };
      
      // üîí PHASE 1 FIX: SAFE MODEL REPLACEMENT - Only replace after validation
      if (status === 'completed') {
        try {
          console.log(`‚úÖ TRAINING COMPLETED: Safely extracting and validating new model for user ${userId}`);
          
          let newModelId = null;
          let newVersionId = null;
          
          // Extract model data from completed training
          if (trainingData.output) {
            // Method 1: Direct model path from training output (preferred for packaged models)
            if (trainingData.output.model) {
              const modelParts = trainingData.output.model.split(':');
              if (modelParts.length === 2) {
                newModelId = modelParts[0];
                newVersionId = modelParts[1];
                console.log(`‚úÖ PHASE 1: Extracted model from output.model: ${newModelId}:${newVersionId}`);
              }
            }
            
            // Method 2: Extract from version URL (fallback)
            if (!newModelId && trainingData.output.version) {
              const versionMatch = trainingData.output.version.match(/([^\/]+\/[^:]+):(.+)$/);
              if (versionMatch) {
                newModelId = versionMatch[1];
                newVersionId = versionMatch[2];
                console.log(`‚úÖ PHASE 1: Extracted model from version URL: ${newModelId}:${newVersionId}`);
              }
            }
          }
          
          // üîí PHASE 1 CRITICAL: Only replace working model if new model is valid
          if (newModelId && newVersionId) {
            // Validate new model format before replacing
            if (newModelId.includes(':') || !newVersionId) {
              console.error(`‚ùå PHASE 1: Invalid model format - modelId: ${newModelId}, versionId: ${newVersionId}`);
              throw new Error('Invalid model format extracted from training');
            }
            
            // üîß PHASE 3: Add model validation before replacement (enhanced safety)
            const isValid = await this.validateModelVersion(newModelId, newVersionId);
            if (!isValid) {
              console.error(`‚ùå PHASE 3: Model validation failed during completion - modelId: ${newModelId}, versionId: ${newVersionId}`);
              throw new Error('Extracted model failed validation test');
            }
            
            // Get existing model for backup logging
            const existingModel = await storage.getUserModelByUserId(userId);
            console.log(`üîí PHASE 1: Replacing model - Previous: ${existingModel?.replicateModelId}:${existingModel?.replicateVersionId}`);
            console.log(`üîí PHASE 1: Replacing model - New: ${newModelId}:${newVersionId}`);
            
            // SAFE REPLACEMENT: Only now replace the working model with validated new model
            updateData.replicateModelId = newModelId;
            updateData.replicateVersionId = newVersionId;
            updateData.completedAt = new Date();
            
            console.log(`‚úÖ PHASE 1 + 3: Model safely replaced after format and API validation for user ${userId}`);
          } else {
            console.error(`‚ùå PHASE 1: Could not extract valid model data from training completion`);
            console.error(`‚ùå PHASE 1: Training output:`, JSON.stringify(trainingData.output, null, 2));
            throw new Error('Failed to extract model data from completed training');
          }
          
        } catch (error) {
          console.error('‚ùå PHASE 1: Failed to safely replace model data:', error);
          // PHASE 1 SAFETY: Keep existing working model if replacement fails
          console.log(`üîí PHASE 1: Preserving existing working model due to replacement failure`);
          updateData.trainingStatus = 'extraction_failed'; // Mark for retry
        }
      }
      
      // üîí PHASE 1: Update trainedModelPath only if we have new model data
      if (status === 'completed' && updateData.replicateModelId) {
        updateData.trainedModelPath = updateData.replicateModelId;
        console.log(`‚úÖ PHASE 1: Updated trainedModelPath to: ${updateData.replicateModelId}`);
      }
      
      await storage.updateUserModel(userId, updateData);
      
      return { status, progress };
      
    } catch (error) {
      throw error;
    }
  }

  // üîß PHASE 3: Retry model extraction for failed trainings
  static async retryModelExtraction(userId: string): Promise<{ success: boolean; message: string }> {
    try {
      console.log(`üîß PHASE 3: Attempting model extraction retry for user ${userId}`);
      
      const userModel = await storage.getUserModelByUserId(userId);
      if (!userModel || !userModel.trainingId) {
        throw new Error('No training found for user');
      }

      // Only allow retry for extraction_failed status
      if (userModel.trainingStatus !== 'extraction_failed') {
        throw new Error(`Cannot retry extraction for status: ${userModel.trainingStatus}`);
      }

      // Get training data from Replicate
      const trainingResponse = await fetch(`https://api.replicate.com/v1/trainings/${userModel.trainingId}`, {
        headers: {
          'Authorization': `Token ${process.env.REPLICATE_API_TOKEN}`,
          'Content-Type': 'application/json'
        }
      });

      if (!trainingResponse.ok) {
        throw new Error(`Failed to fetch training data: ${trainingResponse.status}`);
      }

      const trainingData = await trainingResponse.json();
      
      if (trainingData.status !== 'succeeded') {
        throw new Error(`Training is not in succeeded state: ${trainingData.status}`);
      }

      // üîß PHASE 3: Apply the same extraction logic as completion detection
      let newModelId = null;
      let newVersionId = null;
      
      if (trainingData.output) {
        // Method 1: Direct model path from training output
        if (trainingData.output.model) {
          const modelParts = trainingData.output.model.split(':');
          if (modelParts.length === 2) {
            newModelId = modelParts[0];
            newVersionId = modelParts[1];
            console.log(`‚úÖ PHASE 3: Extracted model from output.model: ${newModelId}:${newVersionId}`);
          }
        }
        
        // Method 2: Extract from version URL (fallback)
        if (!newModelId && trainingData.output.version) {
          const versionMatch = trainingData.output.version.match(/([^\/]+\/[^:]+):(.+)$/);
          if (versionMatch) {
            newModelId = versionMatch[1];
            newVersionId = versionMatch[2];
            console.log(`‚úÖ PHASE 3: Extracted model from version URL: ${newModelId}:${newVersionId}`);
          }
        }
      }

      // üîß PHASE 3: Validate extracted model before updating
      if (!newModelId || !newVersionId) {
        console.error(`‚ùå PHASE 3: Could not extract valid model data from retry`);
        throw new Error('Failed to extract model data from training');
      }

      // Validate model format
      if (newModelId.includes(':') || !newVersionId) {
        console.error(`‚ùå PHASE 3: Invalid model format - modelId: ${newModelId}, versionId: ${newVersionId}`);
        throw new Error('Invalid model format extracted from training');
      }

      // üîß PHASE 3: Test model validity before replacing (optional additional validation)
      const isValid = await this.validateModelVersion(newModelId, newVersionId);
      if (!isValid) {
        throw new Error('Extracted model failed validation test');
      }

      // üîß PHASE 3: Apply the validated model data
      await storage.updateUserModel(userId, {
        replicateModelId: newModelId,
        replicateVersionId: newVersionId,
        trainedModelPath: newModelId,
        trainingStatus: 'completed',
        completedAt: new Date()
      });

      console.log(`‚úÖ PHASE 3: Model extraction retry successful for user ${userId}`);
      return { 
        success: true, 
        message: `Model extraction successful. New model: ${newModelId}:${newVersionId}` 
      };

    } catch (error) {
      console.error(`‚ùå PHASE 3: Model extraction retry failed for user ${userId}:`, error);
      return { 
        success: false, 
        message: error instanceof Error ? error.message : 'Unknown error during retry' 
      };
    }
  }

  // üìä PHASE 4: Calculate real training progress from Replicate logs and timing
  static async calculateRealTrainingProgress(trainingData: any, userModel: any): Promise<number> {
    try {
      // Get training start time - prefer startedAt or fall back to createdAt
      const trainingStartTime = userModel.startedAt 
        ? new Date(userModel.startedAt).getTime()
        : new Date(userModel.createdAt || new Date()).getTime();
      
      const now = Date.now();
      const trainingDuration = now - trainingStartTime;
      
      // üìä PHASE 4: More realistic training time estimates based on actual data
      // Typical FLUX model training takes 25-35 minutes for 1200 steps
      const thirtyMinutes = 30 * 60 * 1000; // 30 minutes - more realistic baseline
      
      // üìä PHASE 4: Parse real training logs if available
      let logBasedProgress = 0;
      if (trainingData.logs && trainingData.logs.length > 0) {
        const logs = trainingData.logs;
        
        // Look for step progress in logs (e.g., "step 234/1200")
        const stepRegex = /step\s+(\d+)\/(\d+)/i;
        const percentRegex = /(\d+(?:\.\d+)?)%/;
        
        // Find the most recent progress indicator
        for (let i = logs.length - 1; i >= 0; i--) {
          const logEntry = logs[i];
          
          // Try to extract step progress
          const stepMatch = logEntry.match(stepRegex);
          if (stepMatch) {
            const currentStep = parseInt(stepMatch[1]);
            const totalSteps = parseInt(stepMatch[2]);
            logBasedProgress = Math.round((currentStep / totalSteps) * 90); // Cap at 90% until completion
            console.log(`üìä PHASE 4: Found step progress: ${currentStep}/${totalSteps} = ${logBasedProgress}%`);
            break;
          }
          
          // Try to extract percentage progress
          const percentMatch = logEntry.match(percentRegex);
          if (percentMatch) {
            logBasedProgress = Math.min(parseInt(percentMatch[1]), 90); // Cap at 90% until completion
            console.log(`üìä PHASE 4: Found percentage progress: ${logBasedProgress}%`);
            break;
          }
        }
      }
      
      // üìä PHASE 4: Combine time-based and log-based progress for accuracy
      const timeBasedProgress = Math.min(Math.round((trainingDuration / thirtyMinutes) * 85), 85); // Cap time-based at 85%
      
      // Use log-based progress if available and higher, otherwise use time-based
      const combinedProgress = Math.max(logBasedProgress, timeBasedProgress);
      
      // üìä PHASE 4: Enhanced progress stages for better UX
      if (trainingDuration < 2 * 60 * 1000) {
        // First 2 minutes: "Initializing training"
        return Math.min(combinedProgress, 10);
      } else if (trainingDuration < 5 * 60 * 1000) {
        // 2-5 minutes: "Processing training data"
        return Math.min(combinedProgress, 25);
      } else if (trainingDuration < 15 * 60 * 1000) {
        // 5-15 minutes: "Training AI model"
        return Math.min(combinedProgress, 60);
      } else if (trainingDuration < 25 * 60 * 1000) {
        // 15-25 minutes: "Optimizing model"
        return Math.min(combinedProgress, 85);
      } else {
        // 25+ minutes: "Finalizing training"
        return Math.min(combinedProgress, 95);
      }
      
    } catch (error) {
      console.error('üìä PHASE 4: Error calculating real progress:', error);
      // Fallback to time-based progress
      const trainingStartTime = new Date(userModel.createdAt || new Date()).getTime();
      const now = Date.now();
      const trainingDuration = now - trainingStartTime;
      const thirtyMinutes = 30 * 60 * 1000;
      return Math.min(Math.round((trainingDuration / thirtyMinutes) * 100), 95);
    }
  }

  // üìä PHASE 4: Get training stage description for better UX
  static getTrainingStageDescription(progress: number, trainingDuration: number): string {
    if (progress >= 95) {
      return "Finalizing your AI model...";
    } else if (progress >= 85) {
      return "Optimizing model quality...";
    } else if (progress >= 60) {
      return "Training AI to recognize your features...";
    } else if (progress >= 25) {
      return "Processing your photos...";
    } else if (progress >= 10) {
      return "Analyzing your style...";
    } else {
      return "Initializing training...";
    }
  }

  // üîß PHASE 3: Validate model version exists and is accessible
  static async validateModelVersion(modelId: string, versionId: string): Promise<boolean> {
    try {
      console.log(`üîß PHASE 3: Validating model ${modelId}:${versionId}`);
      
      const versionResponse = await fetch(`https://api.replicate.com/v1/models/${modelId}/versions/${versionId}`, {
        headers: {
          'Authorization': `Token ${process.env.REPLICATE_API_TOKEN}`,
          'Content-Type': 'application/json'
        }
      });

      if (!versionResponse.ok) {
        console.error(`‚ùå PHASE 3: Model validation failed: ${versionResponse.status}`);
        return false;
      }

      const versionData = await versionResponse.json();
      
      // Check if version is in valid state
      if (versionData.status && versionData.status !== 'succeeded') {
        console.error(`‚ùå PHASE 3: Model version not ready: ${versionData.status}`);
        return false;
      }

      console.log(`‚úÖ PHASE 3: Model validation successful for ${modelId}:${versionId}`);
      return true;

    } catch (error) {
      console.error(`‚ùå PHASE 3: Model validation error:`, error);
      return false;
    }
  }

  // Generate images using custom prompt - wrapper for backward compatibility
  static async generateCustomPrompt(
    userId: string,
    customPrompt: string,
    count: number = 4
  ): Promise<{ images: string[]; generatedImageId?: number; predictionId?: string }> {
    return this.generateUserImages(userId, customPrompt, count);
  }

  // REMOVED: Category/subcategory prompt conversion functions - Maya's personality now drives content
  // All prompt generation now flows through Maya's AI intelligence for personalized styling

  // REAL IMAGE GENERATION - NO SIMULATION
  static async generateUserImages(
    userId: string,
    customPrompt: string,
    count: number = 4,
    options?: { seed?: number; paramsOverride?: any; categoryContext?: string }
  ): Promise<{ images: string[]; generatedImageId?: number; predictionId?: string }> {
    
    try {
      // üîí PERMANENT ARCHITECTURE VALIDATION - NEVER REMOVE
      ArchitectureValidator.enforceZeroTolerance();
      
      // INDIVIDUAL MODELS ONLY: Every user MUST have their own trained model
      const userModel = await storage.getUserModelByUserId(userId);
      
      if (!userModel || userModel.trainingStatus !== 'completed' || !userModel.replicateVersionId) {
        throw new Error('USER_MODEL_NOT_TRAINED: User must train their AI model before generating images. Individual models required.');
      }
      
      // Validate trigger word exists
      if (!userModel.triggerWord) {
        throw new Error('Model training incomplete - no trigger word available');
      }
      
      // GLOBAL FIX: Use full model:version format like other endpoints
      const fullModelVersion = userModel.replicateVersionId;
      
      // GLOBAL FIX: Prevent null or undefined version IDs affecting ALL users
      if (!fullModelVersion) {
        throw new Error(`CRITICAL: User ${userId} has no version ID. Model: ${userModel.replicateModelId}, Status: ${userModel.trainingStatus}`);
      }
      
      // CRITICAL FIX: Use same format as Maya and unified service
      const modelVersion = `${userModel.replicateModelId}:${fullModelVersion}`;
      console.log(`üîí MODEL TRAINING SERVICE VERSION VALIDATION: Model: ${userModel.replicateModelId}, Version: ${fullModelVersion}, Combined: ${modelVersion}`);
      const triggerWord = userModel.triggerWord;
      
      
      // TASK 2: Add debugging to trace prompt processing
      const promptId = `MAYA-${Date.now()}`;
      console.log(`üîç [${promptId}] MODEL TRAINING SERVICE ENTRY:`);
      console.log(`üè≠ RECEIVED PROMPT FROM MAYA: "${customPrompt.substring(0, 300)}"`);
      
      // Handle prompt formatting and enhancement
      let basePrompt;
      
      if (customPrompt.includes('{trigger_word}')) {
        // Legacy prompt format with placeholder
        basePrompt = customPrompt.replace('{trigger_word}', triggerWord);
        console.log(`üîß [${promptId}] LEGACY FORMAT: Replaced trigger word placeholder`);
      } else if (customPrompt.startsWith(triggerWord)) {
        // Sandra's custom prompts already start with trigger word - use as-is
        basePrompt = customPrompt;
        console.log(`‚úÖ [${promptId}] TRIGGER WORD PRESENT: Using Maya's prompt as-is`);
      } else {
        // Add trigger word to beginning if not present
        basePrompt = `${triggerWord} ${customPrompt}`;
        console.log(`üîß [${promptId}] ADDING TRIGGER: Prepended "${triggerWord}"`);
      }
      
      console.log(`üéØ [${promptId}] BASE PROMPT: "${basePrompt.substring(0, 300)}"`);      
      
      // PHASE 4: SECURE GENDER VALIDATION - Maya handles representation through intelligence
      const user = await storage.getUser(userId);
      if (!user) {
        throw new Error('User not found for image generation');
      }
      
      // SECURE: Validate user gender is legitimate value (no injection possible)
      const validGenders = ['woman', 'man', 'non-binary'] as const;
      const secureGender = validGenders.includes(user.gender as any) ? user.gender : null;
      
      if (secureGender) {
        console.log(`üë§ [${promptId}] SECURE GENDER: User is "${secureGender}" - Maya handled representation in prompt generation`);
      } else {
        console.log(`‚ö†Ô∏è [${promptId}] WARNING: No valid gender data - Maya will use neutral representation`);
      }
      
      // Maya's intelligence already included gender naturally in prompt - no injection needed
      let genderEnhancedPrompt = basePrompt;
      
      console.log(`üéØ [${promptId}] ENHANCED PROMPT: "${genderEnhancedPrompt.substring(0, 300)}"`);      
      
      // PHASE 5: NATURAL SKIN TEXTURE ENHANCEMENT - Professional realistic appearance
      let textureEnhancedPrompt = genderEnhancedPrompt;
      
      // Add natural skin texture for professional realism
      const skinTextureEnhancements = [
        'natural skin texture',
        'realistic skin details', 
        'professional lighting',
        'soft natural shadows',
        'high resolution skin',
        'detailed facial features'
      ];
      
      // Smart enhancement - only add if not already present
      const hasTextureTerms = skinTextureEnhancements.some(term => 
        textureEnhancedPrompt.toLowerCase().includes(term.toLowerCase())
      );
      
      if (!hasTextureTerms) {
        // Add subtle, professional skin texture enhancement
        textureEnhancedPrompt = `${textureEnhancedPrompt}, natural skin texture, professional lighting, realistic skin details`;
        console.log(`‚ú® [${promptId}] TEXTURE ENHANCED: Added natural skin texture for professional realism`);
      } else {
        console.log(`‚ú® [${promptId}] TEXTURE PRESENT: Skin enhancement already in prompt`);
      }
      
      // Additional professional quality enhancements
      if (!textureEnhancedPrompt.toLowerCase().includes('high quality')) {
        textureEnhancedPrompt = `${textureEnhancedPrompt}, high quality, detailed, professional photography`;
        console.log(`üì∏ [${promptId}] QUALITY ENHANCED: Added professional photography terms`);
      }
      
      console.log(`‚ú® [${promptId}] TEXTURE ENHANCED PROMPT: "${textureEnhancedPrompt.substring(0, 300)}"`);
      
      // Personality-first: keep Maya's prompt with gender and texture enhancement, ensure trigger appears once and first
      const finalPrompt = ModelTrainingService.formatPrompt(textureEnhancedPrompt, triggerWord);
      console.log(`üöÄ [${promptId}] PROMPT FORMATTED: ${finalPrompt.length} characters ready for generation`);

      // SINGLE PATH LOGIC: Only packaged models supported for consistency
      // All users must have completed trained models with valid model + version IDs

      // ‚úÖ MAYA PURE INTELLIGENCE: Maya already provides count in her concept creation
      // No need for separate parameter intelligence - Maya handles this in her main response
      console.log(`üéØ MAYA PURE INTELLIGENCE: Using Maya's embedded count intelligence`);
      console.log(`üîç [${promptId}] FINAL PROMPT: ${finalPrompt.length} characters processed`);
      
      // Maya determines optimal count as part of her styling intelligence
      const intelligentParams = { count: count, reasoning: "Maya's integrated styling intelligence" };
      
      // ‚úÖ MAYA PURE INTELLIGENCE: Let Maya specify ALL parameters in her prompt
      // Maya's intelligence includes parameter optimization knowledge - trust her completely
      console.log(`üéØ MAYA PURE INTELLIGENCE: Trusting Maya's complete parameter intelligence`);
      
      // MAYA'S INTELLIGENT FLUX PARAMETERS: Use Maya's personality as single source of truth
      const { MAYA_PERSONALITY } = await import('./agents/personalities/maya-personality.js');
      
      // ‚úÖ MAYA PURE INTELLIGENCE: Delegate all parameter selection to PersonalityManager
      const mayaParams = PersonalityManager.getFluxParameters('maya', 'halfBodyShot');
      const aspectRatio = "4:5"; // Maya's default portrait aspect ratio

      console.log(`üéØ MAYA PURE INTELLIGENCE: Using PersonalityManager for parameter intelligence`);
      
      // Maya will specify parameters naturally in her response if needed
      // FLUX optimization settings with Maya's quality intelligence  
      const merged = {
        aspect_ratio: aspectRatio,
        megapixels: "1", 
        output_format: "png",
        output_quality: 95,
        // CRITICAL FLUX PARAMETERS FOR BEAUTIFUL HANDS AND ANATOMICAL ACCURACY
        guidance_scale: mayaParams.guidance_scale,
        num_inference_steps: mayaParams.num_inference_steps
      };
      
      // Use intelligent count unless explicitly overridden
      const finalCount = intelligentParams.count;
      
      // DYNAMIC SEED GENERATION: No hardcoding, random generation for variety
      const seed = typeof options?.seed === 'number'
        ? options.seed!
        : Math.floor(Math.random() * 1e9);

      console.log(`üéØ MAYA SINGLE PATH: Using packaged model for consistent quality`);

      // PACKAGED MODEL ONLY: Consistent quality for all users
      if (!userModel?.replicateModelId || !userModel?.replicateVersionId) {
        throw new Error("BLOCKED: User model missing required packaged model ID or version. Please complete training first.");
      }
      
      const userModelVersion = `${userModel.replicateModelId}:${userModel.replicateVersionId}`;
      const requestBody = {
        version: userModelVersion,
        input: {
          prompt: finalPrompt,
          num_outputs: finalCount,
          // ‚úÖ FLUX parameters for base model + separate LoRA weights
          guidance_scale: merged.guidance_scale,
          num_inference_steps: merged.num_inference_steps,
          aspect_ratio: merged.aspect_ratio,
          megapixels: merged.megapixels,
          output_format: "png", 
          output_quality: 95,
          seed: seed
          // LoRA weights will be added separately from database storage
        }
      };

      // PACKAGED MODEL GUARD: Ensure we're using trained user models only
      if (requestBody.version.includes("flux-1.1-pro")) {
        throw new Error("BLOCKED: Attempted to use base FLUX model. Only packaged user models allowed.");
      }

      console.log("üöö Replicate payload keys:", Object.keys(requestBody.input), "version:", requestBody.version);
      console.log("üéØ MAYA QUALITY PARAMS: guidance_scale =", requestBody.input.guidance_scale, "steps =", requestBody.input.num_inference_steps, "megapixels =", requestBody.input.megapixels, "(API-compliant)");

      const response = await fetch('https://api.replicate.com/v1/predictions', {
        method: 'POST',
        headers: {
          'Authorization': `Token ${process.env.REPLICATE_API_TOKEN}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody)
      });

      
      const prediction = await response.json();
      
      
      if (!response.ok) {
        throw new Error(`Replicate API error (${response.status}): ${JSON.stringify(prediction)}`);
      }
      
      if (!prediction.id) {
        throw new Error(`No prediction ID returned from Replicate API: ${JSON.stringify(prediction)}`);
      }
      
      // ‚úÖ UNIFIED POLLING STRATEGY: Always return immediately for Maya chat
      // All polling handled by /api/maya/check-generation route
      return {
        images: [],
        predictionId: prediction.id,
      };
      
    } catch (error) {
      throw new Error(`Failed to generate images: ${error.message}`);
    }
  }

  // üéØ MAYA PURE INTELLIGENCE: Absolute minimal formatting to preserve Maya's complete styling intelligence
  static formatPrompt(prompt: string, triggerWord: string): string {
    console.log(`üéØ MAYA PURE INTELLIGENCE: Zero-interference formatting mode activated`);
    
    // Only normalize basic whitespace, preserve ALL Maya content
    const normalizedPrompt = (prompt || "").replace(/\s+/g, " ").trim();

    // Check if trigger word is already properly positioned
    if (normalizedPrompt.startsWith(triggerWord)) {
      console.log(`‚úÖ MAYA PURE INTELLIGENCE: Trigger word already present, using Maya's exact output`);
      return normalizedPrompt;
    } else {
      // Only add trigger word if missing, preserve Maya's complete content
      console.log(`‚úÖ MAYA PURE INTELLIGENCE: Adding trigger word to preserve Maya's complete styling intelligence`);
      return `${triggerWord}, ${normalizedPrompt}`;
    }
  }

  // REMOVED: extractLoRAWeights method - no longer needed for packaged-only approach

  // MAYA'S INTELLIGENT SHOT TYPE DETECTION - LIBERATION FROM HARDCODED RESTRICTIONS
  // ‚úÖ REMOVED: Shot type determination - Maya's intelligence includes framing decisions

  // ‚úÖ REMOVED: Intelligent parameter system - Maya's main response includes all parameter intelligence
  // Maya's single Claude API call handles count and all other decision making
  /*
  private static async getIntelligentParameters(prompt: string, requestedCount: number, userId?: string, categoryContext?: string): Promise<{
    count: number;
    reasoning: string;
  }> {
    try {
      // Import Maya's personality and Claude API connection
      const { PersonalityManager } = await import('./agents/personalities/personality-config');
      // Use Claude API service directly
      const { ClaudeApiServiceSimple } = await import('./services/claude-api-service-simple');
      const claudeService = new ClaudeApiServiceSimple();
      
      // MAYA'S PARAMETER INTELLIGENCE PROMPT WITH CATEGORY CONTEXT
      const categoryGuidance = categoryContext ? `\n\nüì∏ USER'S CATEGORY REQUEST: ${categoryContext}
STYLING FOCUS: Adapt your creative choices to match this SSELFIE Studio category:
- Business: Professional authority and credibility 
- Professional & Authority: Leadership presence
- Lifestyle: Elevated casual and authentic moments
- Casual & Authentic: Natural, unguarded moments
- Story: Narrative-driven imagery 
- Behind the Scenes: Raw authenticity
- Instagram: Social media optimized
- Feed & Stories: Platform-specific content
- Travel: Adventure and destinations
- Adventures & Destinations: Location-specific styling
- Outfits: Fashion-focused styling
- Fashion & Style: Editorial fashion focus
- GRWM: Morning routines and preparation
- Get Ready With Me: Extended preparation content
- Future Self: Aspirational imagery
- Aspirational Vision: Goals and transformation
- B&W: Timeless artistic imagery
- Timeless & Artistic: Classic enduring style
- Studio: Controlled professional environment` : '';

      const mayaParameterPrompt = `${PersonalityManager.getNaturalPrompt('maya')}

üéØ MAYA'S CREATIVE INTELLIGENCE:
You're analyzing this image prompt for optimal generation:
"${prompt}"${categoryGuidance}

MAYA'S FOCUSED STYLING APPROACH:
Based on your complete styling expertise, analyze this prompt for ONE perfect image.

IMPORTANT: Always generate exactly 1 image per concept for optimal user experience:
- Research shows single, perfect images are more impactful than multiple variations
- Reduces decision fatigue and cognitive load  
- Creates cleaner, more professional presentation
- Better mobile experience and faster loading

RESPOND EXACTLY IN THIS JSON FORMAT:
{
  "count": 1,
  "reasoning": "Your warm Maya explanation of why this single perfect image captures the styling vision"
}`;

      console.log(`üéØ MAYA PARAMETER AI: Analyzing prompt for intelligent count selection`);
      
      // Get Maya's AI-driven parameter selection using the correct method
      const mayaResponse = await claudeService.sendMessage(mayaParameterPrompt, `parameter_selection_${Date.now()}`, 'maya', false);
      
      // Extract JSON from Maya's response with comprehensive parsing  
      let mayaChoice;
      try {
        // COMPREHENSIVE APPROACH: Maya's response might have the JSON with extra text
        // Look for the most complete JSON object in the response
        let jsonString = '';
        
        // Try multiple strategies to extract valid JSON
        const strategies = [
          // Strategy 1: Look for complete JSON block
          () => {
            const match = mayaResponse.match(/\{[^{}]*"count"[^{}]*"reasoning"[^{}]*\}/);
            return match ? match[0] : null;
          },
          // Strategy 2: Look for any JSON-like structure
          () => {
            const match = mayaResponse.match(/\{[\s\S]*\}/);
            return match ? match[0] : null;
          },
          // Strategy 3: Manually construct if we find count and reasoning
          () => {
            const countMatch = mayaResponse.match(/"count":\s*(\d+)/);
            const reasoningMatch = mayaResponse.match(/"reasoning":\s*"([^"]+)"/);
            if (countMatch && reasoningMatch) {
              return `{"count": ${countMatch[1]}, "reasoning": "${reasoningMatch[1]}"}`;
            }
            return null;
          }
        ];
        
        // Try each strategy
        for (let i = 0; i < strategies.length; i++) {
          const result = strategies[i]();
          if (result) {
            jsonString = result;
            console.log(`üéØ MAYA JSON: Strategy ${i + 1} succeeded`);
            break;
          }
        }
        
        if (!jsonString) {
          throw new Error('No valid JSON found with any strategy');
        }
        
        // Now parse the extracted JSON
        console.log(`üßπ MAYA JSON EXTRACTED:`, jsonString.substring(0, 200));
        mayaChoice = JSON.parse(jsonString);
        console.log(`‚úÖ MAYA JSON PARSE: Success!`);
        
      } catch (parseError) {
        console.log(`‚ö†Ô∏è MAYA PARAMETER PARSE FAILED, using default count:`, parseError);
        console.log(`üìù MAYA RESPONSE DEBUG (first 300 chars):`, mayaResponse.substring(0, 300));
        
        // Fallback to intelligent count selection - FORCE TO 1
        return {
          count: 1, // Always generate 1 perfect image per concept
          reasoning: "Maya's styling intelligence applied for optimal results - one perfect image per concept"
        };
      }
      
      // Validate Maya's choices - FORCE TO 1 for focused styling (user preference)
      const selectedCount = 1; // Always generate 1 perfect image per concept
      
      console.log(`‚úÖ MAYA PARAMETER AI: Selected ${selectedCount} images - ${mayaChoice.reasoning}`);
      
      return {
        count: selectedCount,
        reasoning: mayaChoice.reasoning || "Maya's AI-driven count selection for optimal styling results"
      };
      
    } catch (error) {
      console.log(`‚ö†Ô∏è MAYA PARAMETER AI FAILED, using default count:`, error);
      
      // Fallback that still respects Maya's intelligence
      return {
        count: 1,
        reasoning: "Maya's focused styling approach - one perfect image per concept"
      };
    }
  }
  */
}