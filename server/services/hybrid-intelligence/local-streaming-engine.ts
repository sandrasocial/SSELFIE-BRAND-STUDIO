/**
 * LOCAL STREAMING ENGINE
 * Generates agent responses from cached patterns and local intelligence
 * Zero Claude API token consumption for technical and known workflows
 */

import { AdvancedMemorySystem, type AgentMemoryProfile } from '../advanced-memory-system';
import { IntelligentContextManager } from '../intelligent-context-manager';
import { CONSULTING_AGENT_PERSONALITIES } from '../../agent-personalities-consulting';

export interface LocalStreamingRequest {
  agentId: string;
  userId: string;
  message: string;
  conversationId: string;
  context?: any;
}

export interface LocalStreamingResponse {
  success: boolean;
  content: string;
  type: 'technical' | 'workflow' | 'cached_pattern' | 'personality_driven';
  confidence: number;
  tokensUsed: number; // Always 0 for local
}

export class LocalStreamingEngine {
  private static instance: LocalStreamingEngine;
  private memorySystem = AdvancedMemorySystem.getInstance();
  private contextManager = IntelligentContextManager.getInstance();
  private patternCache = new Map<string, string>();

  private constructor() {}

  public static getInstance(): LocalStreamingEngine {
    if (!LocalStreamingEngine.instance) {
      LocalStreamingEngine.instance = new LocalStreamingEngine();
    }
    return LocalStreamingEngine.instance;
  }

  /**
   * MAIN LOCAL STREAMING PROCESSOR
   * Attempts to generate full agent response locally
   */
  async processLocalStreaming(request: LocalStreamingRequest): Promise<LocalStreamingResponse> {
    console.log(`üè† LOCAL ENGINE: Processing ${request.agentId} request locally`);

    try {
      // Get agent memory profile
      const memoryProfile = await this.memorySystem.getAgentMemoryProfile(request.agentId, request.userId);
      
      // Get workspace context
      const workspaceContext = await this.contextManager.prepareAgentWorkspace(request.message, request.agentId);

      // Try different local processing strategies
      const strategies = [
        () => this.processKnownWorkflow(request, memoryProfile, workspaceContext),
        () => this.processTechnicalRequest(request, memoryProfile, workspaceContext),
        () => this.processCachedPattern(request, memoryProfile),
        () => this.processPersonalityDriven(request, memoryProfile)
      ];

      for (const strategy of strategies) {
        const result = await strategy();
        if (result.success) {
          console.log(`‚úÖ LOCAL SUCCESS: ${request.agentId} responded via ${result.type}`);
          return result;
        }
      }

      // If no local strategy succeeded
      return {
        success: false,
        content: '',
        type: 'technical',
        confidence: 0,
        tokensUsed: 0
      };

    } catch (error) {
      console.error('Local streaming error:', error);
      return {
        success: false,
        content: '',
        type: 'technical',
        confidence: 0,
        tokensUsed: 0
      };
    }
  }

  /**
   * PROCESS KNOWN WORKFLOWS
   * Handle common development tasks with cached patterns
   */
  private async processKnownWorkflow(
    request: LocalStreamingRequest, 
    memoryProfile: AgentMemoryProfile | null,
    workspaceContext: any
  ): Promise<LocalStreamingResponse> {
    
    const workflows = [
      {
        pattern: /add.*(?:button|component|element)/i,
        response: this.generateAgentVoiceResponse(request, 'add_component', workspaceContext)
      },
      {
        pattern: /fix.*(?:error|issue|bug|problem)/i,
        response: this.generateAgentVoiceResponse(request, 'fix_error', workspaceContext)
      },
      {
        pattern: /create.*(?:file|page|component)/i,
        response: this.generateAgentVoiceResponse(request, 'create_file', workspaceContext)
      },
      {
        pattern: /view.*(?:file|code|implementation)/i,
        response: this.generateAgentVoiceResponse(request, 'view_file', workspaceContext)
      },
      {
        pattern: /update.*(?:code|function|implementation)/i,
        response: this.generateAgentVoiceResponse(request, 'update_code', workspaceContext)
      }
    ];

    for (const workflow of workflows) {
      if (workflow.pattern.test(request.message)) {
        const content = await workflow.response;
        if (content) {
          return {
            success: true,
            content,
            type: 'workflow',
            confidence: 0.9,
            tokensUsed: 0
          };
        }
      }
    }

    return { success: false, content: '', type: 'workflow', confidence: 0, tokensUsed: 0 };
  }

  /**
   * PROCESS TECHNICAL REQUESTS
   * Handle file operations, code analysis, system tasks
   */
  private async processTechnicalRequest(
    request: LocalStreamingRequest,
    memoryProfile: AgentMemoryProfile | null,
    workspaceContext: any
  ): Promise<LocalStreamingResponse> {
    
    const technicalPatterns = [
      /(?:search|find|locate).*(?:file|code|function)/i,
      /(?:check|verify|validate).*(?:status|system|code)/i,
      /(?:run|execute).*(?:command|script|test)/i,
      /(?:analyze|review|examine).*(?:code|system|structure)/i
    ];

    const isTechnical = technicalPatterns.some(pattern => pattern.test(request.message));
    
    if (isTechnical) {
      const content = await this.generateAgentVoiceResponse(request, 'technical_analysis', workspaceContext);

      return {
        success: true,
        content,
        type: 'technical',
        confidence: 0.8,
        tokensUsed: 0
      };
    }

    return { success: false, content: '', type: 'technical', confidence: 0, tokensUsed: 0 };
  }

  /**
   * PROCESS CACHED PATTERNS
   * Use previously learned successful interactions
   */
  private async processCachedPattern(
    request: LocalStreamingRequest,
    memoryProfile: AgentMemoryProfile | null
  ): Promise<LocalStreamingResponse> {
    
    if (!memoryProfile || memoryProfile.learningPatterns.length === 0) {
      return { success: false, content: '', type: 'cached_pattern', confidence: 0, tokensUsed: 0 };
    }

    // Simple pattern matching based on learned patterns
    const relevantPatterns = memoryProfile.learningPatterns.filter(pattern => 
      request.message.toLowerCase().includes(pattern.category.toLowerCase())
    );

    if (relevantPatterns.length > 0) {
      const content = await this.generateAgentVoiceResponse(request, 'cached_pattern', { patterns: relevantPatterns });
      const bestPattern = relevantPatterns.sort((a, b) => b.confidence - a.confidence)[0];

      return {
        success: true,
        content,
        type: 'cached_pattern',
        confidence: bestPattern.confidence,
        tokensUsed: 0
      };
    }

    return { success: false, content: '', type: 'cached_pattern', confidence: 0, tokensUsed: 0 };
  }

  /**
   * PROCESS TOOL-ONLY RESPONSES
   * RESTRICTED: Only handle tool operations, NOT conversations
   */
  private async processPersonalityDriven(
    request: LocalStreamingRequest,
    memoryProfile: AgentMemoryProfile | null
  ): Promise<LocalStreamingResponse> {
    
    // CONVERSATIONS SHOULD NEVER REACH HERE
    console.log(`‚ö†Ô∏è  WARNING: Conversation reached local processing - this should be handled by Claude API`);
    console.log(`üìù MESSAGE: "${request.message}"`);
    
    // Reject conversation processing to force Claude API usage
    return { 
      success: false, 
      content: 'This request requires Claude API processing for authentic agent response', 
      type: 'personality_driven', 
      confidence: 0, 
      tokensUsed: 0 
    };
  }

  /**
   * TOOL OPERATION RESPONSE GENERATOR
   * RESTRICTED: Only for tool operations, NOT conversations
   */
  private async generateAgentVoiceResponse(request: LocalStreamingRequest, taskType: string, context: any): Promise<string> {
    // This should only handle tool operations
    if (taskType === 'personality_driven') {
      return `This conversation requires Claude API processing for authentic ${request.agentId} response.`;
    }

    // For actual tool operations, provide minimal technical response
    return `Tool operation "${request.message}" processed locally to save tokens.`;
  }

  private extractAgentVoicePatterns(personality: any): string[] {
    const systemPrompt = personality.systemPrompt || '';
    const voicePatterns: string[] = [];
    
    // Extract quoted speaking examples from personality
    const quotes = systemPrompt.match(/"([^"]+)"/g) || [];
    quotes.forEach(quote => {
      const cleanQuote = quote.replace(/"/g, '');
      if (cleanQuote.length > 10) { // Filter out short quotes
        voicePatterns.push(cleanQuote);
      }
    });
    
    return voicePatterns;
  }

  private getTaskContext(taskType: string, message: string): string {
    if (taskType === 'add_component') return 'component creation and integration';
    if (taskType === 'fix_error') return 'error diagnosis and resolution';
    if (taskType === 'create_file') return 'file creation and structure';
    if (taskType === 'view_file') return 'code analysis and review';
    if (taskType === 'update_code') return 'code modification and improvement';
    if (taskType === 'technical_analysis') return 'technical analysis and system operations';
    if (taskType === 'cached_pattern') return 'leveraging previous successful patterns';
    if (taskType === 'personality_driven') return 'specialized expertise application';
    return 'development task';
  }

  private generateAuthenticVoice(personality: any, voicePatterns: string[], taskContext: string, userMessage: string): string {
    const name = personality.name;
    const role = personality.role;
    const specialization = personality.specialization || '';
    
    // SIMPLE GREETINGS: Handle social interactions appropriately
    const simpleGreetings = /^(?:hey|hi|hello|how are you|good morning|good afternoon).*$/i;
    if (simpleGreetings.test(userMessage.trim())) {
      // Find a suitable greeting voice pattern or use natural response
      const greetingPatterns = voicePatterns.filter(pattern => 
        pattern.length < 100 && 
        !pattern.includes('implement') && 
        !pattern.includes('database') &&
        !pattern.includes('schema')
      );
      
      if (greetingPatterns.length > 0) {
        const greeting = greetingPatterns[0];
        return `${greeting} I'm doing great and ready to tackle any technical challenges you have for SSELFIE Studio!`;
      }
      
      return `Hey Sandra! I'm doing excellent and ready to dive into any backend architecture or technical work you need. What can I help you build today?`;
    }
    
    // TECHNICAL TASKS: Use appropriate voice patterns
    if (voicePatterns.length > 0) {
      // Find relevant patterns that match the task context
      const relevantPatterns = voicePatterns.filter(pattern => 
        !simpleGreetings.test(pattern) && pattern.length > 20
      );
      
      if (relevantPatterns.length > 0) {
        const selectedPattern = relevantPatterns[Math.floor(Math.random() * relevantPatterns.length)];
        const baseStyle = selectedPattern.replace(/\.\.\.$/, '').trim();
        
        return `${baseStyle} I'll handle this systematically using my expertise in ${specialization}.

Let me analyze your request and provide you with the optimal solution...

*[Processing with enterprise intelligence and zero-cost operations]*`;
      }
    }
    
    // Fallback using agent identity without generic templates
    return `I understand you need assistance with ${taskContext}. As ${name}, your ${role}, I'll apply my specialized knowledge to help you achieve this.

Let me examine the situation and implement the best approach for your specific needs.

*[Proceeding with intelligent analysis and tool execution]*`;
  }

  private extractTaskType(message: string): string {
    if (/file/i.test(message)) return 'file operations';
    if (/code/i.test(message)) return 'code analysis';
    if (/system/i.test(message)) return 'system operations';
    if (/error/i.test(message)) return 'error resolution';
    return 'development task';
  }
}