## Basic model info

Model name: black-forest-labs/flux-dev-lora
Model description: A version of flux-dev, a text to image model, that supports fast fine-tuned lora inference


## Model inputs

- prompt (required): Prompt for generated image (string)
- aspect_ratio (optional): Aspect ratio for the generated image (string)
- image (optional): Input image for image to image mode. The aspect ratio of your output will match this image (string)
- prompt_strength (optional): Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image (number)
- num_outputs (optional): Number of outputs to generate (integer)
- num_inference_steps (optional): Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster. (integer)
- guidance (optional): Guidance for generated image (number)
- seed (optional): Random seed. Set for reproducible generation (integer)
- output_format (optional): Format of the output images (string)
- output_quality (optional): Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs (integer)
- disable_safety_checker (optional): Disable safety checker for generated images. (boolean)
- go_fast (optional): Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16. Note that outputs will not be deterministic when this is enabled, even if you set a seed. (boolean)
- lora_weights (optional): Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>[/<lora-weights-file.safetensors>], CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet, including signed URLs. For example, 'fofr/flux-pixar-cars'. Civit AI and HuggingFace LoRAs may require an API token to access, which you can provide in the `civitai_api_token` and `hf_api_token` inputs respectively. (string)
- lora_scale (optional): Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora. (number)
- extra_lora (optional): Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars' (string)
- extra_lora_scale (optional): Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora. (number)
- megapixels (optional): Approximate number of megapixels for generated image (string)
- hf_api_token (optional): HuggingFace API token. If you're using a hf lora that needs authentication, you'll need to provide an API token. (string)
- civitai_api_token (optional): Civitai API token. If you're using a civitai lora that needs authentication, you'll need to provide an API token. (string)


## Model output schema

{
  "type": "array",
  "items": {
    "type": "string",
    "format": "uri"
  },
  "title": "Output"
}

If the input or output schema includes a format of URI, it is referring to a file.


## Example inputs and outputs

Use these example outputs to better understand the types of inputs the model accepts, and the types of outputs the model returns:

### Example (https://replicate.com/p/30k587n6shrme0ck4zzrr6bt6c)

#### Input

```json
{
  "prompt": "a bacon cheeseburger in the style of TOK a trtcrd, tarot style",
  "go_fast": true,
  "guidance": 3,
  "lora_scale": 1,
  "megapixels": "1",
  "num_outputs": 1,
  "aspect_ratio": "1:1",
  "lora_weights": "huggingface.co/multimodalart/flux-tarot-v1",
  "output_format": "webp",
  "output_quality": 80,
  "prompt_strength": 0.8,
  "num_inference_steps": 28
}
```

#### Output

```json
[
  "https://replicate.delivery/xezq/MIF2XaWOzOZ7DVu4KsxRv4US2mHxoSWYlCeiiFCS78foFvwTA/out-0.webp"
]
```


## Model readme

> ![](https://tjzk.replicate.delivery/markdownx/44d3556c-2848-45d3-8bbb-8be67da8ba3e.jpg)
> 
> `FLUX.1 [dev]` is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions.
> For more information, please read our [blog post](https://blackforestlabs.ai/announcing-black-forest-labs/).
> 
> # Key Features
> 1. Cutting-edge output quality, second only to our state-of-the-art model `FLUX.1 [pro]`.
> 2. Competitive prompt following, matching the performance of closed source alternatives .
> 3. Trained using guidance distillation, making `FLUX.1 [dev]` more efficient.
> 4. Open weights to drive new scientific research, and empower artists to develop innovative workflows.
> 5. Generated outputs can be used for personal, scientific, and commercial purposes as described in the [flux-1-dev-non-commercial-license](https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md).
> 
> # Usage
> We provide a reference implementation of `FLUX.1 [dev]`, as well as sampling code, in a dedicated [github repository](https://github.com/black-forest-labs/flux).
> Developers and creatives looking to build on top of `FLUX.1 [dev]` are encouraged to use this as a starting point.
> 
> ## ComfyUI
> `FLUX.1 [dev]` is also available in [Comfy UI](https://github.com/comfyanonymous/ComfyUI) for local inference with a node-based workflow.
> 
> # Limitations
> - This model is not intended or able to provide factual information.
> - As a statistical model this checkpoint might amplify existing societal biases.
> - The model may fail to generate output that matches the prompts.
> - Prompt following is heavily influenced by the prompting-style.
> 
> # Out-of-Scope Use
> The model and its derivatives may not be used
> 
> - In any way that violates any applicable national, federal, state, local or international law or regulation.
> - For the purpose of exploiting, harming or attempting to exploit or harm minors in any way; including but not limited to the solicitation, creation, acquisition, or dissemination of child exploitative content.
> - To generate or disseminate verifiably false information and/or content with the purpose of harming others.
> - To generate or disseminate personal identifiable information that can be used to harm an individual.
> - To harass, abuse, threaten, stalk, or bully individuals or groups of individuals.
> - To create non-consensual nudity or illegal pornographic content.
> - For fully automated decision making that adversely impacts an individual's legal rights or otherwise creates or modifies a binding, enforceable obligation.
> - Generating or facilitating large-scale disinformation campaigns.
> 
> # Accelerated Inference
> We provide a `go_fast` flag within the API which toggles a version of flux-schnell optimized for inference. Currently this version is a compiled fp8 quantization with an optimized attention kernel, which quantizes and fuses lora weights with base model weights at generation time. We'll update the model and this documentation as we develop further enhancements. 
> 
> # License
> If you generate images on Replicate with FLUX.1 models and their fine-tunes, then you can use the images commercially.
> 
> If you download the weights off Replicate and generate images on your own computer, you can't use the images commercially.

